//! Functions related to parsing of various Values

use crate::error::Error;
use crate::token_types::{TokenChecker, TokenType};
use crate::tokenizer::Token;

use super::utils::{expect_token, expect_token_one_of};

// Parses a given set of 'tokens' as a value and returns a string corresponding to one that would
// be generated by concatenating those tokens. Note: It should be possible to regenerate, original
// tokens, by 'tokenize'ing the string.
pub(super) fn parse_value<'parser>(tokens: &'parser [Token]) -> Result<(String, usize), Error> {
    if !expect_token_one_of(
        tokens,
        &[
            Token::is_identifier,
            Token::is_numeric,
            Token::is_bitstring,
            Token::is_hexstring,
            Token::is_tstring,
            Token::is_curly_begin,
            Token::is_round_begin,
        ],
    )? {
        Err(unexpected_token!(
            "'IDENTIFIER', 'NUMBER', 'Bit String', 'Hex String', 'String', '{', '('",
            tokens[0]
        ))
    } else {
        let token = &tokens[0];
        match token.r#type {
            TokenType::Identifier
            | TokenType::NumberInt
            | TokenType::BitString
            | TokenType::HexString
            | TokenType::TString => Ok((token.text.clone(), 1)),
            _ => parse_set_ish_value(tokens),
        }
    }
}

fn parse_set_ish_value<'parser>(tokens: &'parser [Token]) -> Result<(String, usize), Error> {
    let (begin_token, end_token): (TokenChecker, TokenChecker) =
        if expect_token(tokens, Token::is_curly_begin)? {
            (Token::is_curly_begin, Token::is_curly_end)
        } else {
            (Token::is_round_begin, Token::is_round_end)
        };

    let mut level = 0;
    let mut consumed = 0;

    loop {
        if expect_token(&tokens[consumed..], begin_token)? {
            level += 1;
        }
        consumed += 1;
        if expect_token(&tokens[consumed..], end_token)? {
            level -= 1;
            consumed += 1;
            if level == 0 {
                return Ok((Token::concat(&tokens[0..consumed]), consumed));
            }
        }
        consumed += 1;
    }
}

// TODO: Add Test cases
